## ScrapeGraphAI: Extract Information Using Custom Scraping Pipelines
Summary: ScrapeGraphAI provides various scraping pipelines for extracting information from the web. The SmartScraperGraph uses a direct graph implementation to execute user queries, incorporating OpenAI or Google Gemini models. Prettification options allow for formatting the results in JSON format. SpeechGraph combines scraping with text-to-speech functionality. Additionally, users can build their own custom graphs or utilize GraphBuilder for automated graph creation based on user prompts. The library also includes nodes for internet search, scraping, and text-to-speech generation.

Link: https://colab.research.google.com/drive/1sEZBonBMGP44CtO6GQTwAlL0BGJXjtfd?usp=sharing

<img src="/img/908f37a8-86d3-4b65-87d5-9d21636c27e5.png" width="400" />


<sup><sub>5/9/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10565_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10565_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10565_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## LangChain Collaborates with FreeCodeCamp for Comprehensive Gen AI Training
Summary: LangChain, a company that offers an educational course on building projects with its AI framework, is hosting a masterclass on leveraging LangChain for Generative AI projects. The 4-hour course, available on freeCodeCamp.org's YouTube channel, is highly recommended by industry experts and provides practical wisdom and training on mastering AI frameworks and methodologies.

Link: https://www.linkedin.com/posts/langchain_learn-langchain-and-gen-ai-by-building-activity-7190734076683681792-VAgI?utm_source=share&amp;utm_medium=member_android

<img src="/img/da0553f4-8e3c-4f2f-9d34-0ed9017c201d.png" width="400" />


<sup><sub>4/30/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10527_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10527_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10527_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Multi-Agent RAG YouTube Workshop to Explore Complex Problem-Solving with LangChain
Summary: LangChain is hosting a workshop on multi-agent reinforcement learning (RAG), where attendees will delve into the concept of combining independent agents to solve complex problems. The workshop will cover patterns such as planning, reflection, and tool use, and showcase LangGraph, a library for orchestrating multi-actor applications with large language models.

Link: https://www.linkedin.com/posts/langchain_multi-agent-rag-luma-activity-7190832191080169472-YDnF?utm_source=share&amp;utm_medium=member_android

<img src="/img/d75fd190-6bb5-4067-9775-473814e70cd3.png" width="400" />


<sup><sub>4/30/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10524_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10524_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10524_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Hugging Face Delivers Phi-3-mini-4k-Instruct, a State-of-the-Art 3.8B Parameter Model for Inference
Summary: Phi-3-Mini-4K-Instruct is a lightweight, state-of-the-art language model trained with diverse data sources, including synthetic data and quality-filtered websites. It has undergone post-training fine-tuning to enhance its instruction following and safety capabilities. The model has demonstrated strong performance in benchmarks for common sense reasoning, language understanding, math, code, long context, and logical reasoning. It supports the chat format and is designed for use in memory-constrained environments, latency-bound scenarios, and applications requiring strong reasoning abilities. Developers should consider potential limitations and responsibly use the model in alignment with ethical guidelines and applicable regulations.

Link: https://huggingface.co/microsoft/Phi-3-mini-4k-instruct

<img src="/img/a4c250de-5e92-42a4-930d-3bd7c1f55f23.png" width="400" />


<sup><sub>4/24/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10486_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10486_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10486_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Upload and use media files for prompting with the Gemini API
Summary: The Gemini API enables text, image, and audio prompting (multimodal prompting). To use large images, videos, and audio in prompts, the File API can be leveraged to store files up to 2GB in size and up to 20GB per project (stored for 48 hours). The File API supports a variety of media MIME types, and uploaded files can be referenced in Gemini API calls through a unique URI. Upon file upload, the API can be queried to verify receipt of files, and manual deletion is also possible. Specific model versions support prompting with image, audio, or video formats, with limitations and requirements for each format (e.g., image size, audio duration).

Link: https://ai.google.dev/gemini-api/docs/prompting_with_media

<img src="/img/896d61e0-cfb0-4171-a89a-c368679830b1.png" width="400" />


<sup><sub>4/18/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10459_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10459_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10459_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## LLM Pioneer Mixtral AI Highlights Usage and Customization for Enhanced AI Integration
Summary: Mistral AI has emerged as a leading player in the AI realm with its Large Language Model (LLM), Mixtral 8x7B, which adopts the Mixture-of-Experts (MoE) concept. Open-sourced under the Apache 2.0 license, Mixtral 8x7B enables developers to customize and enhance the model based on their specific needs. This customization is facilitated by Ollama, an open-source software that simplifies the installation and operation of AI models on local computers. By leveraging PDF documents and a vector database (Qdrant), Mixtral 8x7B can specialize in specific domains, as demonstrated by the example of generating code tailored for Spring Boot 3.2. This combination of performance, flexibility, and accessibility empowers developers to seamlessly integrate AI into their projects while safeguarding their data through local execution.

Link: https://scalastic.io/en/mixtral-ollama-llamaindex-llm/

<img src="/img/96b3f6da-9eaa-41c2-8415-64591109004f.png" width="400" />


<sup><sub>4/8/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10381_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10381_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10381_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Build Scalable AI Agents with Large Language Models (LLMs) Through a Self-Paced Online Course
Summary: Deep Learning Institute offers a free, self-paced online course on "Building RAG Agents with LLMs," covering strategies for deploying and scaling retrieval-based LLM agents. The course requires a basic understanding of LLMs and LangChain, as well as intermediate Python experience. It explores the implementation and development of microservices, dialog management, and document retrieval solutions. The course also provides hands-on experience with state-of-the-art models and guidance for productionalization and framework exploration.

Link: https://courses.nvidia.com/courses/course-v1:DLI+S-FX-15+V1/

<img src="/img/76f19a78-8052-4c3e-bdf1-be6402a3df5a.png" width="400" />


<sup><sub>3/25/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10294_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10294_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10294_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Run Mixtral 8x7B Locally: A Comprehensive Guide for Deployment and Usage
Summary: Mixtral 8x7B, a GPT-4 like large language model (LLM), can be locally deployed using suitable computing resources such as an NVIDIA GeForce RTX 4090 GPU and 64GB RAM. After installing the necessary Python libraries and downloading the model files, you can initialize and test Mixtral using a Jupyter Notebook environment. The model can be fine-tuned with specific instructions to handle complex tasks like text summarization and translation. An alternative method for Mac users involves utilizing LlamaIndex and Ollama to set up and run Mixtral 8x7B, facilitating data indexing and querying. Additionally, you can use Anakin AI to access multiple open-source LLMs, including Mistral 7B and 8x7B, for online testing and development.

Link: https://anakin.ai/blog/how-to-run-mixtral-8x7b-locally/

<img src="/img/95c5525f-9f90-4bd8-85b5-fb8de6ed24a6.png" width="400" />


<sup><sub>3/8/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10216_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10216_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10216_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Information Extraction via Firework Function Calling
Summary: .

Link: https://colab.research.google.com/github/fw-ai/cookbook/blob/main/examples/function_calling/fireworks_functions_information_extraction.ipynb#scrollTo=MdU98plyfdZ1

<img src="/img/d92b2bc4-38f7-41b6-af0b-fe5b86e9815c.png" width="400" />


<sup><sub>2/25/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10159_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10159_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10159_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Txtai: Extracting and Building Knowledge Using Language Models and Knowledge Graphs
Summary: The article discusses the process of building knowledge graphs using LLM-driven entity extraction. It demonstrates how to load a Wikipedia database, perform entity extraction using an LLM prompt, build a graph network from the extracted entities, visualize the network, and traverse the graph to find specific paths. This approach combines automatically derived relationships via semantic similarity with manually specified ones to create powerful knowledge graphs.

Link: https://neuml.hashnode.dev/build-knowledge-graphs-with-llm-driven-entity-extraction

<img src="/img/0cffaa32-1436-4e80-8a22-c00217c34b32.png" width="400" />


<sup><sub>2/21/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10134_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10134_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10134_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Introducing NVIDIA Chat with RTX: A Personalized AI Chatbot on Your RTX PC
Summary: NVIDIA Chat with RTX is a demo app that integrates a large language model with user-provided content to create a personalized chatbot. It utilizes retrieval-augmented generation and RTX acceleration to provide fast and relevant answers to queries. Users can input text documents, PDFs, URLs, and YouTube playlists into the app's library, and developers can access the underlying technology through the TensorRT-LLM RAG reference project on GitHub. Chat with RTX is available for Windows PCs and workstations with NVIDIA RTX GPUs and requires Windows 11, an RTX 30 or 40 Series GPU with at least 8GB of VRAM, and 16GB or more RAM.

Link: https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/

<img src="/img/3eeaeac7-7a77-4cd3-b47e-6e05b40c498b.png" width="400" />


<sup><sub>2/20/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10118_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10118_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10118_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Groq: Offering API Access to the World's Fastest Open-Source LLM Inference Engine
Summary: Groq provides API access to approved members, offering the fastest inference speed for open-source LLMs, including Llama 2 70B, with a 10-day free trial. Groq guarantees the most competitive pricing and offers additional models like Mistral and CodeLlama upon request. Their LPU Inference Engine boasts an 18x faster LLM inference performance compared to cloud providers, as demonstrated on Anyscale's LLMPerf Leaderboard.

Link: https://wow.groq.com/

<img src="/img/56ff21cb-ede1-4b7d-aa59-4a47582bfdc5.png" width="400" />


<sup><sub>2/19/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10107_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10107_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10107_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Open-Source AI Cookbook repository providing practical AI implementation examples using open-source tools and models.
Summary: The Open-Source AI Cookbook is a community-driven repository that provides practical AI examples and tutorials using open-source tools and models. Contributors can submit ideas, contribute notebooks, or improve existing content. To contribute, review existing notebooks to avoid duplication and ensure that the notebook is practical, clearly written, executes without errors, adds to existing recipes, and references all resources used. Once a pull request is merged, the notebook will be added to the cookbook, which is accessible online at huggingface.co/learn/cookbook.

Link: http://github.com/huggingface/cookbook

<img src="/img/99c08a64-c82f-41ae-a8ee-fcebfbc2a416.png" width="400" />


<sup><sub>2/16/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10099_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10099_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10099_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## LoRA: Low-Rank Adaptation of Large Language Models
Summary: LoRA (Low-Rank Adaptation of Large Language Models) is a method for adapting large language models to new tasks by learning a low-rank update for a subset of the model's parameters while keeping the remaining parameters fixed. This approach significantly reduces the number of trainable parameters and enables efficient task switching during deployment. LoRA has been shown to outperform several other adaptation methods and is comparable or superior to full fine-tuning on various benchmarks.

Link: https://github.com/microsoft/LoRA

<img src="/img/bf1612e7-5608-4729-bd69-c2ee27ebeaca.png" width="400" />


<sup><sub>2/13/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10081_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10081_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10081_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## MetaVoice-1B: A Powerful 1.2B Parameter Base Model for Text-to-Speech
Summary: MetaVoice-1B is a 1.2B parameter text-to-speech model with a focus on emotional speech rhythm and tone in English, support for voice cloning with finetuning, and zero-shot cloning for American and British voices. It predicts EnCodec tokens from text and speaker information and uses a causal GPT to predict the first two hierarchies of EnCodec tokens. The rest of the 6 hierarchies are predicted using a non-causal transformer. Multi-band diffusion is used to generate waveforms from the EnCodec tokens, and DeepFilterNet is used to clean up artifacts introduced by the diffusion process.

Link: https://huggingface.co/metavoiceio/metavoice-1B-v0.1

<img src="/img/48b63e33-12aa-4568-8697-d9ec42db232b.png" width="400" />


<sup><sub>2/7/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10050_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10050_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10050_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## New programming language optimizes prompts for large language models
Summary: LMQL, a programming language designed specifically for interacting with Large Language Models (LLMs), has just released version 0.7. It enables robust and modular LLM prompting with features such as types, templates, constraints, and an optimizing runtime. Programmers can write queries in LMQL, which are then sent to an LLM to generate responses. The results are directly accessible, enabling the construction of complex prompts with guaranteed output formats. Moreover, LMQL supports nested queries, modularized local instructions, and re-use of prompt components, making it a powerful tool for prompt engineering.

Link: https://lmql.ai/

<img src="/img/4ed56468-4916-4da4-b17e-a90567bb6ce7.png" width="400" />


<sup><sub>1/20/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9930_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9930_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9930_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## From scratch implementation of Self-Attention, Multi-Head Attention, Cross-Attention, and Causal Self-Attention in Large Language Models (LLMs)
Summary: This article explains the inner workings of the self-attention mechanism, a core component of large language models (LLMs) like GPT-4 and Llama, through a step-by-step coding approach. It also covers multi-head attention, cross-attention, and causal self-attention.

Link: https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention

<img src="/img/fc744586-928d-47fd-bd8e-87045144ad19.png" width="400" />


<sup><sub>1/15/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9895_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9895_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9895_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Explore topics, data connectivity and run network analysis with the Semantic Graph
Summary: A semantic graph, also known as a knowledge graph or semantic network, is introduced, constructed with semantic relationships connecting the nodes. Nodes and relationships can be added to the graph, and analysis functions can be run on it. Semantic graphs can be used to explore relationships, such as topics and interconnections in a dataset. Embeddings instances can be indexed into a graph, allowing for network analysis and topic modeling. Topic modeling can be done using community detection algorithms, and centrality and pagerank can be used to analyze the graph. The graph can also be traversed to show how nodes are connected. Furthermore, images can be grouped into topics using topic modeling, and the image graph can be walked to explore relationships between images.

Link: https://neuml.hashnode.dev/introducing-the-semantic-graph

<img src="/img/b9351921-70a5-4365-aec2-52c9c1ba5b74.png" width="400" />


<sup><sub>1/15/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9889_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9889_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9889_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Portkey's AI Gateway: Access 100+ LLMs with Unified API
Summary: Portkey's AI Gateway functions as an interface between applications and hosted Large Language Models, enabling streamlined API requests to various providers. It features a unified API signature for over 100 LLMs, allowing developers to connect using the OpenAI API signature without code modifications. Additional features include automatic retries, fallbacks, load balancing, and multiple SDKs for easy integration. Configurable routing strategies offer customization for fallbacks, retries, and load balancing.

Link: https://github.com/Portkey-AI/gateway

<img src="/img/9010a57f-f609-41d0-984d-09bda68172c1.png" width="400" />


<sup><sub>1/13/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9877_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9877_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9877_0&tag=Experiments)<sub/><sup/>

<br/><br/>

