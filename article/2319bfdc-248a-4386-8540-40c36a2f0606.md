## Hugging Face's Whisper gets 5x faster for fine-tuning with LoRA and PEFT
Summary: Announcing a significant 5x speed-up improvement for Whisper fine-tuning, enabled by LoRA and PEFT. This optimization allows for larger batch sizes, enabling tuning of the Whisper-large checkpoint on GPUs with less than 8GB VRAM. Remarkably, this acceleration is achieved with minimal degradation in WER (Word Error Rate).

Link: https://www.linkedin.com/feed/update/urn:li:activity:7064229705507332096?utm_source=share&utm_medium=member_android

<img src="/img/2319bfdc-248a-4386-8540-40c36a2f0606.png" width="400" />
<br/><br/>
