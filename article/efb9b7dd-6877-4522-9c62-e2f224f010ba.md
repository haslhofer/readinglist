## Neural Architecture of Speech
Summary: This text presents a study on how well different speech representation learning models encode speech stimuli and align with brain activations. By using ridge regression to train models that predict brain responses from speech representations, the study finds that both contrastive and predictive models perform better than generative models and traditional non-deep learning methods. Specifically, the predictive model Data2Vec exhibits the best performance, significantly outperforming all other models in aligning with both auditory and language brain regions. Additionally, the study demonstrates that speech models capture the auditory hierarchy with early layers explaining early auditory cortex and middle and later layers explaining high-level auditory areas. These findings provide insights into the neural architecture of speech processing and suggest that predictive models like Data2Vec offer promising avenues for brain encoding tasks.

Link: https://drive.google.com/file/d/1sW3bjke7XeOU0anVb68LgSYhM4bVBs4Q/view

<img src="/img/efb9b7dd-6877-4522-9c62-e2f224f010ba.png" width="400" />
<br/><br/>
