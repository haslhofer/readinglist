## Deploy the FLAN-T5 XXL language model with bnb quantization on Amazon SageMaker for real-time inference
Summary: The guide provides instructions for deploying the FLAN-T5-XXL model on Amazon SageMaker for real-time inference using the Hugging Face Inference Deep Learning Container. The model is sharded in fp16 format and weighs around 30GB. Hugging Face transformers and Amazon SageMaker are used together to create a custom inference script and upload the model artifact to Amazon S3. The deployed model is available for endpoint creation, and the guide explains how to run inference using a JSON payload and how to pass additional parameters to customize the generation process. Finally, instructions for deleting the model and endpoint are also provided.

Link: https://www.philschmid.de/deploy-flan-t5-sagemaker

<img src="/img/4a35de03-9228-4598-b6e3-5d32a6755be7.png" width="400" />
<br/><br/>
