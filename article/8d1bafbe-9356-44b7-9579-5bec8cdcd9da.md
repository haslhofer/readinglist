## Advanced RAG: Optimizing Retrieval with Additional Context & MetaData using LlamaIndexðŸ¦™
Summary: Retrieval Augmented Generation (RAG) augments large language models (LLMs) with additional data, often private or real-time, to enable reasoning about specific information. RAG involves loading and indexing data, splitting text into smaller chunks, creating vector embeddings, storing the indexed data, and querying it using LLMs. Advanced RAG techniques enhance context and retrieval efficiency, such as parent-child chunks retrieval, where smaller chunks are retrieved for better search quality while retaining the context from larger chunks. The implementation involves data loading, chunking, selecting an open-source LLM and embedding, creating a baseline retriever, integrating chunk references, and storing indexed data. Evaluation can be performed to compare different retrievers and select the optimal one.

Link: https://akash-mathur.medium.com/advanced-rag-optimizing-retrieval-with-additional-context-metadata-using-llamaindex-aeaa32d7aa2f

<img src="/img/8d1bafbe-9356-44b7-9579-5bec8cdcd9da.png" width="400" />
<br/><br/>
