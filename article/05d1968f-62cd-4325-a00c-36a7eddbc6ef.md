## Standard NLP benchmarks may not be adequate for evaluating chatty LLM models
Summary: Nazneen Rajani published a post on LinkedIn where she discussed the effectiveness of standard NLP benchmarks in assessing chatty LLMs. She emphasized that while these benchmarks are suitable for evaluating pretraining and in-context learning, they are not sufficient for SFT (Sequence-to-Sequence Fine-Tuning) or RLHF (Reinforcement Learning from Human Feedback) models. Rajani provided an example of how RedPajama and Falcon, two SFT models, scored differently on certain tasks highlighting the limitations of current benchmark systems. Additionally, she raised the concern that the existing leaderboard may not accurately reflect the usefulness of a particular LLM.

Link: https://www.linkedin.com/feed/update/urn:li:activity:7071964874351792128?utm_source=share&amp;utm_medium=member_android

<img src="/img/05d1968f-62cd-4325-a00c-36a7eddbc6ef.png" width="400" />
<br/><br/>
