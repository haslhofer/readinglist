## AI Model Can Learn From Images and Text Without Fine-tuning
Summary: Researchers introduced Kosmos-1, a Multimodal Large Language Model (MLLM) trained on web-scale multimodal corpora, such as text, images, and image-caption pairs. Kosmos-1 demonstrated impressive performance in various tasks across language understanding, perception-language tasks (e.g., image captioning and visual question answering), and vision tasks (e.g., image recognition with descriptions). It can also benefit from cross-modal transfer and diagnose nonverbal reasoning capabilities via the newly introduced Raven IQ test dataset.

Link: https://arxiv.org/abs/2302.14045

<img src="/img/7e5412e9-486e-47b4-b9b9-f03e6c802fac.png" width="400" />
<br/><br/>
