## Running Mistral AI's Mixtral 8x7b on a laptop is now simplified with Ollama and LlamaIndex
Summary: To use Mistral AI's Mixtral 8x7b model on a laptop, users can employ Ollama in conjunction with LlamaIndex to establish a retrieval-augmented generation application locally, complete with an API. This setup offers an open-source solution for retrieval-augmented generation.

Link: https://www.linkedin.com/posts/llamaindex_running-mistral-ais-mixtral-8x7b-on-your-activity-7143670975811706880-HXqb?utm_source=share&amp;utm_medium=member_android

<img src="/img/96afadb6-d786-4b2d-bce7-8218176d0243.png" width="400" />
<br/><br/>
