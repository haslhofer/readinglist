## Large Language Model-Based Multimodal Agent Navigates and Operates Smartphone Apps
Summary: The paper introduces a novel LLM-based multimodal agent framework, AppAgent, capable of operating smartphone applications through a simplified action space, mimicking human-like interactions. The agent learns to navigate and use new apps through autonomous exploration or observation of human demonstrations, generating a knowledge base for executing complex tasks across various applications. Extensive testing demonstrated its proficiency in handling diverse high-level tasks in different applications.

Link: https://arxiv.org/abs/2312.13771

<img src="/img/c8a67575-012e-41ac-af56-b5ec15c8a922.png" width="400" />
<br/><br/>
