## Microsoft's E5 model outperforms OpenAI's embedding model in terms of performance, cost, and customizability
Summary: This article introduces the concept of embedding models in the context of generative AI, highlighting their role in processing text bite by bite when the context length of large language models (LLMs) is limited. It discusses the OpenAI embedding model, text-embedding-ada-002, and its limitations in terms of performance and fine-tuning capabilities. The article then introduces the Embeddings from Bidirectional Encoder Representations (E5) model as a better alternative, emphasizing its strengths in performance, size, and fine-tuning capabilities. The author provides a detailed explanation of how to host an E5 model on a GCP compute engine instance, including the necessary code and instructions. The article concludes by comparing the speed and cost of the E5 model with the OpenAI model, highlighting the advantages of the E5 model.

Link: https://medium.com/@kelvin.lu.au/hosting-a-text-embedding-model-that-is-better-cheaper-and-faster-than-openais-solution-7675d8e7cab2

<img src="/img/6dc550c0-e9cc-42dd-90cc-1635929de677.png" width="400" />
<br/><br/>
