## OpenAI's LongLoRA technique extends the context window of open-source LLMs to 100k tokens, enabling advanced use cases like RAG models.
Summary: LongLoRA, a new training technique, has been developed to extend the context windows of open LLMs. This allows for improved performance on tasks such as question answering and summarizing. The training technique is computationally efficient and can be used to extend the context window of LLM to 100,000 tokens without performance degradation. It is also compatible with existing attention mechanisms and optimization techniques. The LongLoRA training dataset for extending context is also released.

Link: https://www.linkedin.com/posts/andrew-iain-jardine_opensource-llms-activity-7112405451916398594-tZ_5?utm_source=share&amp;utm_medium=member_android

<img src="/img/198482e3-e42a-4831-b759-5ee70994ae1b.png" width="400" />
<br/><br/>
