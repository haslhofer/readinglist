## Open-Source Language Models Tackle the Challenge of Extending Context Length
Summary: Currently, commercial LLMs have a greater context length compared to open-source LLMs. OpenAI's GPT-3.5 has a context length of 16k, GPT-4 has 32k, and Anthropic's Claude up to 100k, while Meta LLaMa and Falcon only have a context length of 2k. However, it is possible to extend the context length of open-source models like LLaMa either post-pre-training or during pre-training, as explored in two blog posts: "Extending Context is Hard...but not Impossible" and "The Secret Sauce behind 100K context window in LLMs: all tricks in one place."

Link: https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_open-source-llms-are-behind-commercial-models-activity-7078287712683708416-ZtQz?utm_source=share&amp;utm_medium=member_android

<img src="/img/e72d5973-91ec-45af-8bda-fba068d30267.png" width="400" />
<br/><br/>
