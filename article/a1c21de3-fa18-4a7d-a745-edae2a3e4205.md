## Hugging Face releases an impressive vision-language model that outperforms larger closed-source models
Summary: Researchers at Tsinghua University in China have developed CogVLM, an impressive vision-language model that rivals and even outperforms larger closed-source models like Google's PaLi-X 55B on several benchmarks. CogVLM is available for commercial use and is compatible with the Hugging Face Transformers library, making it accessible to a wide range of developers and researchers. The model achieves state-of-the-art or second-best performance on 14 classic cross-modal benchmarks, despite being significantly smaller than other models, with only 17 billion parameters.

Link: https://www.linkedin.com/posts/huggingface_gpt-4-with-vision-is-cool-but-it-has-some-activity-7134204742364196865-k_26?utm_source=share&utm_medium=member_android

<img src="/img/a1c21de3-fa18-4a7d-a745-edae2a3e4205.png" width="400" />
<br/><br/>
