## Automatic Evaluation Framework for Assessing LLMs' Protocol Planning Abilities in Biology
Summary: The paper presents a novel automatic evaluation framework and dataset called BioProt for assessing the performance of Large Language Models (LLMs) in planning experimental protocols in biology. The framework involves converting natural language protocols into pseudocode representations, which enables the evaluation of an LLM's ability to reconstruct the pseudocode from high-level descriptions and admissible pseudocode functions. The study explores the performance of GPT-3 and GPT-4 on this task and examines their robustness. It also demonstrates the utility of pseudocode representations by generating accurate novel protocols and successfully executing a generated protocol in a biological laboratory. The extensibility of the framework to other areas of science or domains lacking automatic evaluation is highlighted.

Link: https://arxiv.org/abs/2310.10632?utm_source=substack&utm_medium=email

<img src="/img/38d1a3b5-34b5-4974-bf30-dc849cad863c.png" width="400" />
<br/><br/>
