## 4-bit GPTQ-for-LLaMa model with ActOrder, Group Size, Safetensors and Triton support
Summary: Young Geng's Koala 13B GPTQ is a large-scale language model trained by TheBloke. It provides multiple GPTQ parameter permutations allowing users to choose the best one for their hardware and requirements. These models were quantized using hardware kindly provided by Latitude.sh. They are compatible with AutoGPTQ, GPTQ-for-LLaMa, and Occ4m's GPTQ-for-LLaMa fork. ExLlama works with Llama models in 4-bit precision.

Link: https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g

<img src="/img/8837c3e6-ffeb-4370-8130-b685f606f724.png" width="400" />
<br/><br/>
