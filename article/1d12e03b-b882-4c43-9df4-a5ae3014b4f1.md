## Multimodal Pretraining with Microsoftâ€™s BEiT-3
Summary: Multi-way transformers, as seen in Microsoft's BEiT-3 model, help in multimodal pretraining. Modalities are ways of communicating information; in simpler terms, they are the different data formats AI models can understand. These transformers allow for six modalities in ImageBind, twelve in Meta-Transformer, and handle text as the primary modality in Composable Diffusion. Videos demonstrating the performance of these models can be found in the post.

Link: https://www.linkedin.com/posts/manishsgupta_multimodal-pretraining-with-microsofts-beit-activity-7096246246465564672-6H5l?utm_source=share&amp;utm_medium=member_android

<img src="/img/1d12e03b-b882-4c43-9df4-a5ae3014b4f1.png" width="400" />
<br/><br/>
