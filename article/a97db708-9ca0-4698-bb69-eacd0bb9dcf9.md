## Study explores self-rewarding language models that continuously improve both instruction following and self-reward provision
Summary: Researchers propose Self-Rewarding Language Models (SRLM), where the LLM itself provides rewards during training. SRLM outperforms existing systems on the AlpacaEval 2.0 leaderboard, including Claude 2, Gemini Pro, and GPT-4 0613, demonstrating the potential for models to continually improve both instruction following and reward provision abilities.

Link: https://arxiv.org/abs/2401.10020

<img src="/img/a97db708-9ca0-4698-bb69-eacd0bb9dcf9.png" width="400" />
<br/><br/>
