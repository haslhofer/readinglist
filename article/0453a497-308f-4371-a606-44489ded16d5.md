## Open-Source Vision-Language Model CogVLM Rivals Closed-Source Competitors
Summary: Researchers at Tsinghua University in China have released CogVLM, an impressive open-source vision-language model compatible with the Hugging Face Transformers library. Despite its smaller size of 17 billion parameters, CogVLM rivals or surpasses much larger closed-source models from Google on various cross-modal benchmarks. It achieves state-of-the-art or second-best performance on 14 classic benchmarks by utilizing trainable visual experts added to a frozen large language model. The model is available for commercial use and is planned to be integrated into the Transformers library.

Link: https://www.linkedin.com/posts/huggingface_gpt-4-with-vision-is-cool-but-it-has-some-activity-7134204742364196865-k_26?utm_source=share&utm_medium=member_android

<img src="/img/0453a497-308f-4371-a606-44489ded16d5.png" width="400" />
<br/><br/>
