## Run Mistral AI's Mixtral 8x7b retrieval-augmented generation model locally with Ollama and LlamaIndex
Summary: LlamaIndex has created a blog post detailing how to use Ollama with LlamaIndex to set up a fully functional retrieval-augmented generation app locally. The app features an API and includes an option to fine-tune the model. The blog post also discusses the hardware requirements for running the app, as well as the availability of a quantized version of the model for those with limited RAM.

Link: https://www.linkedin.com/posts/llamaindex_running-mistral-ais-mixtral-8x7b-on-your-activity-7143670975811706880-HXqb?utm_source=share&amp;utm_medium=member_android

<img src="/img/c14c0a63-de79-4c0c-9ffb-e9cdec81fbf8.png" width="400" />
<br/><br/>
