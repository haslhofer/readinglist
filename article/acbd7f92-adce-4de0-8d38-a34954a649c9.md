## Two New Large Open-Source Language Models from TII: Falcon 7B and 40B Push the Boundaries of Natural Language Processing
Summary: TII has released two new open-source LLMs called Falcon: a 7B model trained on 1.5 trillion tokens and a 40B model trained on 1 trillion tokens. Falcon outperforms comparable open-source models thanks to its extensive training on refined web data. It uses FlashAttention, multi-query Attention, and a 2048 context window. The license allows commercial use with limitations. The models are available on Hugging Face and have already been updated to Apache 2.0.

Link: https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_new-open-source-llms-the-falcon-has-landed-activity-7067841408451104768-BAqq?utm_source=share&utm_medium=member_android

<img src="/img/acbd7f92-adce-4de0-8d38-a34954a649c9.png" width="400" />
<br/><br/>
