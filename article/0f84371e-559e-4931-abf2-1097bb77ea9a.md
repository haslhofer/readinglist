## DocLLM: A layout-aware generative language model for multimodal document understanding
Summary: DocLLM is a lightweight extension to large language models (LLMs) for reasoning over visual documents, considering both textual semantics and spatial layout by decomposing attention matrices and pretraining on text infilling for irregular layouts using a large-scale instruction dataset. It outperforms existing LLMs on 14 out of 16 datasets across four core document intelligence tasks and generalizes well to new datasets.

Link: https://arxiv.org/abs/2401.00908

<img src="/img/0f84371e-559e-4931-abf2-1097bb77ea9a.png" width="400" />
<br/><br/>
