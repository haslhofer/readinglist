## Cerebras releases open-source version of its large language model trained on PILE Dataset
Summary: Emad Barsoum, a LinkedIn user, announced the release of a trained version of GPT-3, an AI model, ranging from 111MB to 13B parameters, under the Apache 2.0 license. This model was developed using the PILE Dataset accelerated by Cerebras Wafer-Scale Clusters, and is now available as open-source for research or commercial applications, without any royalty fees.

Link: https://www.linkedin.com/posts/ebarsoum_cerebras-cerebras-activity-7046571544940064768-amSS?utm_source=share&utm_medium=member_android

<img src="/img/d23d9efe-fdd9-403c-b345-b5a275d44206.png" width="400" />
<br/><br/>
