## Small LLMs Under-13B: The Rising Stars of Open Language Models
Summary: The emergence of smaller LLMs with impressive performance has reshaped the AI landscape in 2023, challenging the understanding of efficiency and capability in AI. These models have shown remarkable performance despite their reduced scale, exhibiting capabilities in code completion, instruction following, chat, and reasoning tasks, among others. They are also more resource-efficient and accessible to researchers and developers, offering opportunities to explore the power of language in more efficient ways. The article highlights specific smaller LLMs across different parameter sizes, discussing their unique contributions, training data, architecture, performance, and potential applications. These models, including DeciCoder-1B, Phi-1.5, Dolly v2-3b, StableLM Zephyr 3B, DeciLM-7B, Mistral-7B-Instruct-v0.2, Orca 2, Amber, OpenHathi-7B-Hi-v0.1-Base, SOLAR-10.7B-v1.0, and NexusRaven-V2-13B, showcase the diversity and potential of smaller LLMs in advancing the field of natural language processing.

Link: https://deci.ai/blog/small-giants-top-10-under-13b-llms-in-open-source/

<img src="/img/3818d806-3e34-4ab9-ae37-ebf099937aa6.png" width="400" />
<br/><br/>
