## LoRA: Low-Rank Adaptation of Large Language Models
Summary: LoRA (Low-Rank Adaptation of Large Language Models) is a method for adapting large language models to new tasks by learning a low-rank update for a subset of the model's parameters while keeping the remaining parameters fixed. This approach significantly reduces the number of trainable parameters and enables efficient task switching during deployment. LoRA has been shown to outperform several other adaptation methods and is comparable or superior to full fine-tuning on various benchmarks.

Link: https://github.com/microsoft/LoRA

<img src="/img/bf1612e7-5608-4729-bd69-c2ee27ebeaca.png" width="400" />
<br/><br/>
