## Meta-Free UI Task Automation API via Reinforced Instruction Grounding
Summary: This paper introduces a multimodal model for grounding natural language instructions in User Interface (UI) screenshots for generic UI task automation. The model, comprising a visual encoder and language decoder, is trained using a pixel-to-sequence paradigm to predict geometric coordinates from UI screenshots in token sequences. An innovative Reinforcement Learning (RL) algorithm is employed to jointly supervise token sequences with visual semantic metrics, enhancing the spatial decoding capability of the model. This approach outperforms current methods and demonstrates potential as a generic UI task automation API.

Link: https://arxiv.org/abs/2310.04716

<img src="/img/524431d9-3c84-429f-97c0-23295fb76c4d.png" width="400" />
<br/><br/>
