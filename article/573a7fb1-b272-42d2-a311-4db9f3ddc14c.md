## Run Mistral language models locally or via APIs using LLM
Summary: Simon Willison discusses various methods for using Mistral AI's language models locally on personal devices using the LLM command-line tool. He provides detailed instructions for using Mistral 8x7B and Mistral 7B models via different plugins and API providers, including llama.cpp, llm-llama-cpp, llm-mistral, and more. Additionally, he mentions the availability of Mistral models on the La plateforme API and explores options for using the OpenAI API endpoint through Llamafile. Willison highlights the convenience and flexibility of LLM plugins for supporting diverse language models and encourages users to explore the available options based on their needs.

Link: https://simonwillison.net/2023/Dec/18/mistral/

<img src="/img/573a7fb1-b272-42d2-a311-4db9f3ddc14c.png" width="400" />
<br/><br/>
