## DocLLM: A Generative Language Model for Multimodal Document Understanding
Summary: DocLLM, a lightweight extension to large language models (LLMs) for multimodal document understanding, incorporates spatial layout information by decomposing the attention mechanism in classical transformers into a set of disentangled matrices. Trained on a large-scale instruction dataset, it outperforms state-of-the-art LLMs on 14 out of 16 datasets across four core document intelligence tasks and generalizes well to unseen datasets.

Link: https://arxiv.org/abs/2401.00908

<img src="/img/89a5190d-080f-4449-a3ff-2eafbff90c7b.png" width="400" />
<br/><br/>
