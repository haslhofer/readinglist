## LM Studio: Run Local Large Language Models with OpenAI-Compatible API Server
Summary: LM Studio allows you to load Large Language Models (LLMs) on your local machine and access them through an API server on localhost. The API follows OpenAI's format, so you can use it with code that currently uses OpenAI by pointing it to localhost:PORT. By loading an LLM in LM Studio and starting the server, you can send requests to perform inferencing tasks such as chat completions using various parameters supported by OpenAI's API.

Link: https://lmstudio.ai/docs/local-server

<img src="/img/cd79cc64-50da-4fb4-b407-338deec8f506.png" width="400" />
<br/><br/>
