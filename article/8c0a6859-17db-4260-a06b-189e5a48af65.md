## Researchers compare the benefits and drawbacks of bitsandbytes and GPTQ, two quantization methods supported in Transformers
Summary: The post shares a comparison between the two quantization schemes supported in the transformers library, bitsandbytes and auto-gptq. Bitsandbytes is easier to use but slower for text generation compared to auto-gptq. Auto-gptq, on the other hand, allows for quantization up to 2 bits, but it requires a calibration dataset and works only for language models as of now. The blog concludes that bitsandbytes is better suited for fine-tuning, while auto-gptq is better for text generation, and provides a possible workflow for achieving the best of both worlds.

Link: https://huggingface.co/blog/overview-quantization-transformers

<img src="/img/8c0a6859-17db-4260-a06b-189e5a48af65.png" width="400" />
<br/><br/>
