## OMMO: A Large-scale Outdoor Multi-modal Dataset and Benchmark for Novel View Synthesis and Implicit Scene Reconstruction
Summary: The OMMO dataset consists of outdoor multimodal data collected from captured and YouTube videos, including calibrated images, point clouds, and prompt annotations. It provides a benchmark for outdoor NeRF-based tasks like novel view synthesis, surface reconstruction, and multi-modal NeRF. The dataset contains various scenes with different scales, camera trajectories, and lighting conditions, and is annotated with text descriptions. It aims to facilitate research on realistic scene understanding and generation.

Link: https://ommo.luchongshan.com/

<img src="/img/195d00d9-b810-440b-9c02-b65706e8f942.png" width="400" />
<br/><br/>
