## LLMTools: Finetuning Large Language Models on Consumer GPUs
Summary: LLMTools is an open-source Python library for running and finetuning large language models (LLMs) on consumer GPUs. It features support for 2-bit, 3-bit, and 4-bit quantization using the LP-LoRA algorithm, an easy-to-use API for quantization, inference, and finetuning, and modular support for multiple LLMs, quantizers, and optimization algorithms. LLMTools also allows users to share their LLMs on the Hugging Face Hub.

Link: https://github.com/kuleshov-group/llmtune?utm_source=marktechpost-newsletter.beehiiv.com&utm_medium=newsletter&utm_campaign=exciting-ai-updates-unleash-the-power-of-llms-offline-for-document-queries-discover-the-latest-advancement-in-llms-with-consumer-gpus-introducing-stability-ai-s-open-source-text-to-animation-tool

<img src="/img/6943e62e-efb2-47df-8436-24eca8f68d5b.png" width="400" />
<br/><br/>
