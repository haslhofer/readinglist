## ScrapeGraphAI: Extract Information Using Custom Scraping Pipelines
Summary: ScrapeGraphAI provides various scraping pipelines for extracting information from the web. The SmartScraperGraph uses a direct graph implementation to execute user queries, incorporating OpenAI or Google Gemini models. Prettification options allow for formatting the results in JSON format. SpeechGraph combines scraping with text-to-speech functionality. Additionally, users can build their own custom graphs or utilize GraphBuilder for automated graph creation based on user prompts. The library also includes nodes for internet search, scraping, and text-to-speech generation.

Link: https://colab.research.google.com/drive/1sEZBonBMGP44CtO6GQTwAlL0BGJXjtfd?usp=sharing

<img src="/img/908f37a8-86d3-4b65-87d5-9d21636c27e5.png" width="400" />


<sup><sub>5/9/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10565_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10565_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10565_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Mistral AI Releases Updated 7.3B Parameter Model for Instruct and Text Completion
Summary: Mistral AI has released the 0.2 version of their 7B parameter model, Mistral 7B, under an Apache license. This model outperforms Llama 2 13B and Llama 1 34B on several benchmarks, with performance comparable to CodeLlama 7B on code-related tasks while maintaining proficiency in English language tasks. Mistral 7B supports both instruction following and text completion modes, accessible via command-line or API integration.

Link: https://ollama.com/library/mistral

<img src="/img/5084651b-7d2b-4874-a881-b650d381d8e1.png" width="400" />


<sup><sub>5/6/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10556_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10556_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10556_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## BANG: Unlocking Billion-Scale Approximate Nearest Neighbor Search on a Single GPU
Summary: BANG, a groundbreaking GPU-based Approximate Nearest Neighbor Search (ANNS) method, efficiently handles billion-scale datasets that exceed GPU memory capacity. By leveraging compressed data on the GPU for distance computations and maintaining the graph on the CPU, BANG optimizes GPU kernels and executes concurrently on the GPU and CPU. BANG outperforms existing techniques in most cases, with significantly higher throughputs (40x-200x) for high recall values (0.9) on billion-size datasets.

Link: https://arxiv.org/abs/2401.11324

<img src="/img/d8d6b663-1423-4a14-9055-1fe653d51bf7.png" width="400" />


<sup><sub>4/30/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10529_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10529_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10529_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## ScrapeGraphAI: Automating Web Scraping with Language Learning Models
Summary: ScrapeGraphAI is a Python library that simplifies web scraping by employing large language models (LLMs) to automate the creation of scraping pipelines for websites, documents, and XML files. By simply specifying the desired information to extract, the library leverages LLMs to generate the necessary scraping code, eliminating the complexities associated with traditional web scraping tools.

Link: https://www.linkedin.com/posts/langchain_scrapegraphai-you-only-scrape-once-activity-7190356584525451265-wh2Q?utm_source=share&amp;utm_medium=member_android

<img src="/img/b6505e4a-4a59-4633-9a93-cce482b7df23.png" width="400" />


<sup><sub>4/30/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10522_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10522_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10522_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Tesla abandons plans for $25,000 electric car, focuses on robotaxi platform
Summary: Tesla has reportedly abandoned plans for its $25,000 "Model 2" electric vehicle, shifting its focus to a new robotaxi platform. Despite Elon Musk's long-standing promise of an affordable EV, the company has prioritized its next-generation vehicle platform and the development of a fully autonomous robotaxi, believing that the latter would make a low-cost vehicle obsolete. Tesla's strategic shift comes amid increasing competition from Chinese automakers and its loss of the top global EV producer title to BYD.

Link: https://www.theverge.com/2024/4/5/24122064/tesla-cancel-affordable-electric-vehicle-model-2-china

<img src="/img/b9e2b682-a2d4-4b65-81ad-674ffa4bc39b.png" width="400" />


<sup><sub>4/5/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10347_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10347_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10347_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Calendars Can Be Time Machines: Exploring New Layers and Dimensional Time Management
Summary: Calendars, essential tools for time management, have remained largely static despite technological advancements. They fail to distinguish between different event types, such as tasks, meetings, and blocked time, and lack the ability to integrate data from other sources. This essay proposes introducing native layers to calendars that would allow for the seamless integration of various activities, including Spotify listening history, sleep quality data, and personal activities from the past. By enhancing calendars' capabilities to accommodate diverse data layers, they can transform into actual time machines, enabling users to shape the future through insights gained from past experiences and unlock a range of new productivity use cases.

Link: https://julian.digital/2023/07/06/multi-layered-calendars/

<img src="/img/8fa53570-9c8e-4f96-ad96-c3e6ccf63472.png" width="400" />


<sup><sub>3/6/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10205_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10205_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10205_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## StructLM: Advancing LLMs for Structured Knowledge Grounding
Summary: The StructLM project aims to enhance Structured Knowledge Grounding (SKG) capabilities in Large Language Models (LLMs). Researchers created a comprehensive instruction tuning dataset and trained a series of models (StructLM-7B to StructLM-34B) based on the Code-LLaMA architecture. StructLM excels on 14 out of 18 evaluated SKG datasets, setting new state-of-the-art achievements on 7 tasks. However, researchers found that increasing model size beyond StructLM-7B offered marginal benefits, suggesting that advancing SKG требует more innovative approaches.

Link: https://tiger-ai-lab.github.io/StructLM/

<img src="/img/f82bef1d-0a32-4c95-8b00-2ac184deb024.png" width="400" />


<sup><sub>3/3/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10189_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10189_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10189_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Getting Started with DSPy: A Comprehensive Guide to LLM Programming
Summary: This video tutorial by Connor Shorten introduces the DSPy programming language, which simplifies the creation of language models by compiling declarative calls into pipelines. The video covers key aspects of DSPy development, including installation, data management with dspy.Example, LLM metrics, the DSPy programming model, and optimization techniques, making it a comprehensive resource for getting started with DSPy programming.

Link: https://youtu.be/CEuUG4Umfxs?si=86Gp7CKV3PuBzpds

<img src="/img/1818d5d3-b3db-4532-9872-402b4a63745c.png" width="400" />


<sup><sub>2/29/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10178_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10178_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10178_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Fireworks introduces FireFunction-v1, an open-weights, GPT-4-level function calling model for faster and accurate decision-making.
Summary: Fireworks released FireFunction-v1, a new and improved open-weights model based on Mixtral. This model offers several advantages over its predecessor, including higher accuracy for real-world use cases, improved response accuracy for multilingual inputs, and the ability to configure "tool_choice" to 'any' to force a function call. It also outperforms other OSS models in terms of speed and accuracy and is available for free during a limited beta period. Additionally, it supports structured output generation and routing decision-making, making it a versatile tool for developers building LLM applications.

Link: https://fireworks.ai/blog/firefunction-v1-gpt-4-level-function-calling

<img src="/img/a4ef1d51-980c-45ef-80da-27b49674adfa.png" width="400" />


<sup><sub>2/25/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10155_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10155_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10155_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Demystifying Transformers: Unveiling the Mechanisms of ChatGPT, GPT-4, and LLaMa
Summary: Transformers are a type of neural network architecture that has become increasingly popular for natural language processing tasks. They are used in a variety of applications, including machine translation, text summarization, and question answering. Transformers learn context and relationships in sequential data through an attention mechanism, allowing them to understand the meaning of words and phrases in context. At inference time, Transformers use a stack of encoder and decoder layers to generate text or translate languages, while during training, these layers are optimized using backpropagation to minimize a loss function.

Link: https://www.youtube.com/watch?v=IGu7ivuy1Ag

<img src="/img/b3db696d-c00c-4398-bebc-ca825c2f8960.png" width="400" />


<sup><sub>2/22/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10140_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10140_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10140_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Introducing NVIDIA Chat with RTX: A Personalized AI Chatbot on Your RTX PC
Summary: NVIDIA Chat with RTX is a demo app that integrates a large language model with user-provided content to create a personalized chatbot. It utilizes retrieval-augmented generation and RTX acceleration to provide fast and relevant answers to queries. Users can input text documents, PDFs, URLs, and YouTube playlists into the app's library, and developers can access the underlying technology through the TensorRT-LLM RAG reference project on GitHub. Chat with RTX is available for Windows PCs and workstations with NVIDIA RTX GPUs and requires Windows 11, an RTX 30 or 40 Series GPU with at least 8GB of VRAM, and 16GB or more RAM.

Link: https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/

<img src="/img/3eeaeac7-7a77-4cd3-b47e-6e05b40c498b.png" width="400" />


<sup><sub>2/20/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10118_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10118_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10118_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Surya: Document OCR Toolkit Featuring Accurate OCR and Line-Level Text Detection
Summary: Surya is an OCR toolkit that accurately extracts text and lines from documents in over 90 languages. It outperforms Tesseract in terms of speed, accuracy, and coverage. Surya is designed for OCR on printed text but may work on some handwritten images. It supports text extraction from images, PDFs, and folders and can also visualize the detected text lines.

Link: https://github.com/VikParuchuri/surya

<img src="/img/10e86b52-4ff6-4910-a6d8-34d0afa16104.png" width="400" />


<sup><sub>2/19/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10115_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10115_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10115_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Hugging Face Researchers Train One of the Largest Context Size Transformers on Long Video and Language Sequences
Summary: Researchers have developed a large transformer model that can process over 1 million tokens of video and language sequences. The model, trained on a massive dataset using the RingAttention technique, improves long sequence understanding and retrieval tasks. The authors also provide open-sourced 7B parameter models for text and video processing, addressing challenges such as memory constraints, computational complexity, and data limitations. This work enables broader AI capabilities for assisting humans by combining human textual knowledge with the physical world's understanding.

Link: https://huggingface.co/papers/2402.08268

<img src="/img/3f867aaf-26a2-47a5-9061-c1fe77a06a78.png" width="400" />


<sup><sub>2/17/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10103_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10103_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10103_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Meta releases Code Llama 70B, a large language model achieving human-level performance on code generation tasks.
Summary: Meta released Code Llama 70B, the largest version of Code Llama, an AI system designed for programming tasks. It has achieved 67.8% on the HumanEval benchmark, matching the initial performance of the recently-hyped GPT-4. Code Llama 70B is initialized from Llama 2, trained on 1T Tokens, and fine-tuned on Python and Instruct versions. It has a context window of 16384 and is available on Hugging Face, with plans to integrate it into Hugging Chat soon.

Link: https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_code-llama-70b-is-heremeta-just-activity-7157780231116738562-GlmI?utm_source=share&amp;utm_medium=member_android

<img src="/img/f0b117f2-83fe-4a0b-a3c3-6135c48c2e52.png" width="400" />


<sup><sub>1/29/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10008_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10008_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=10008_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Colab Notebook Runs Mixtral8x7B-Instruct Model with MoE Offloading for Text Generation
Summary: The provided text uses a pre-trained quantized model, Mixtral-8x7B-Instruct, implemented with a mixed-precision strategy and a specific offloading approach, making it suitable for inference on consumer-grade GPUs or in Google Colab with limited VRAM and RAM resources. It outlines the process of setting up the environment, initializing the model, and generating text sequences interactively, demonstrating its language generation capabilities. The text also includes a couple of funny poems in response to user prompts, showcasing the model's ability to generate creative text based on user input.

Link: https://colab.research.google.com/github/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb#scrollTo=f7qY7ebqX7T7

<img src="/img/a1ccacca-62c9-4256-85fa-d60954da19e7.png" width="400" />


<sup><sub>1/20/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9932_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9932_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9932_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## New programming language optimizes prompts for large language models
Summary: LMQL, a programming language designed specifically for interacting with Large Language Models (LLMs), has just released version 0.7. It enables robust and modular LLM prompting with features such as types, templates, constraints, and an optimizing runtime. Programmers can write queries in LMQL, which are then sent to an LLM to generate responses. The results are directly accessible, enabling the construction of complex prompts with guaranteed output formats. Moreover, LMQL supports nested queries, modularized local instructions, and re-use of prompt components, making it a powerful tool for prompt engineering.

Link: https://lmql.ai/

<img src="/img/4ed56468-4916-4da4-b17e-a90567bb6ce7.png" width="400" />


<sup><sub>1/20/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9930_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9930_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9930_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Two Sigma's New Guide to Large Language Model Abstractions
Summary: This research focuses on the recent developments in frameworks that abstract interactions with large language models (LLMs). The authors introduce a seven-layer abstraction model, the Language Model System Interface Model (LMSI), to classify these frameworks and their separation of concerns. They also identify five families of LM abstractions based on their intrinsic and extrinsic features, which include utilities, community resources, reliability, performance, portability, and extensibility. This article provides a comprehensive review of existing LM programming abstractions and offers insights for developers and framework designers. It also includes a table and a figure to further illustrate the key features and terms discussed.

Link: https://www.twosigma.com/articles/a-guide-to-large-language-model-abstractions/

<img src="/img/6655ed24-80f5-4844-a139-41662586fea3.png" width="400" />


<sup><sub>1/19/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9928_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9928_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9928_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Using External Data, Pinecone Serverless Improves Large Language Models
Summary: The research presented demonstrates that using Retrieval-Augmented Generation (RAG) significantly improves the quality of responses generated by Large Language Models (LLMs), such as GPT-4 and Llama 2, even when dealing with questions that fall within the LLM's training domain. As more data is integrated into the RAG system, the performance of LLMs improves, with a remarkable 13% enhancement in the faithfulness of answers observed in GPT-4 when supplemented with RAG over a billion-record corpus. Furthermore, the study highlights that different LLMs, regardless of their size or complexity, can achieve comparable levels of accuracy and reliability when combined with RAG, democratizing access to state-of-the-art generative AI capabilities.

Link: https://www.pinecone.io/blog/rag-study/

<img src="/img/480f3a6f-3964-4cdd-8d2a-fc017c4e3aec.png" width="400" />


<sup><sub>1/19/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9924_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9924_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9924_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Sure, here's a one-line headline describing the text you provided:

**Government Unveils Plan to Combat Physician Burnout and Improve Patient Care**
Summary: I do not have access to external websites or specific documents, including the text you are referring to. Therefore, I am unable to summarize the text for you.

Link: https://www.wsj.com/tech/samsung-galaxy-s24-artificial-intelligence-features-dc37e134?mod=tech_trendingnow_article_pos1

<img src="/img/29de4cd2-f593-4da1-847f-a5a984f00b99.png" width="400" />


<sup><sub>1/18/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9916_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9916_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9916_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Hugging Face multimodal team releases Websight, a dataset of screenshots and HTML/CSS code for training Vision Language Models.
Summary: Hugging Face released Websight, a dataset of 823,000 website screenshots and HTML/CSS code for training Vision Language Models (VLMs) to convert images to code. The dataset is generated using open models and can be used commercially. A fine-tuned open model is also available for free on Hugging Face.

Link: https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_transform-screenshots-into-html-code-effortlessly-activity-7152949221824872449-62iJ?utm_source=share&amp;utm_medium=member_desktop

<img src="/img/eb0d2ae7-8591-4ef9-933b-8b62eb6f3acb.png" width="400" />


<sup><sub>1/16/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9905_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9905_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9905_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## From scratch implementation of Self-Attention, Multi-Head Attention, Cross-Attention, and Causal Self-Attention in Large Language Models (LLMs)
Summary: This article explains the inner workings of the self-attention mechanism, a core component of large language models (LLMs) like GPT-4 and Llama, through a step-by-step coding approach. It also covers multi-head attention, cross-attention, and causal self-attention.

Link: https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention

<img src="/img/fc744586-928d-47fd-bd8e-87045144ad19.png" width="400" />


<sup><sub>1/15/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9895_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9895_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9895_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## This article lists recommended books of various genres, all of which promise to expand readers' minds.
Summary: This repository contains a list of mind-expanding books curated by various contributors. The selection covers a wide range of topics, including startups and business, philosophy and psychology, autobiographies and biographies, history, science and medicine, logic and problem-solving, politics, economics, gender, sexuality, race, education, writing, theater and film, Shakespeare, fiction, and miscellaneous subjects like health, design, travel, language, nature, and art. Some popular book recommendations are Shoe Dog by Phil Knight, The Ride of a Lifetime by Robert Iger, and Bad Blood by John Carreyrou.

Link: https://github.com/hackerkid/Mind-Expanding-Books

<img src="/img/9e8c5f7b-a2eb-403f-8998-875c15b5938d.png" width="400" />


<sup><sub>1/15/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9893_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9893_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9893_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Open-source, Highly Accurate Optical Character Recognition (OCR) System Released
Summary: A new open-source Optical Character Recognition (OCR) tool called Surya has been released, which accurately extracts text from images and supports multiple languages. It can recognize text at the line level, making it a valuable tool for tasks such as document processing and data extraction.

Link: https://www.linkedin.com/posts/alexcarliera_a-new-highly-accurate-ocr-was-just-released-activity-7151966210732040192-MeDq?utm_source=share&amp;utm_medium=member_android

<img src="/img/5a96af17-2a6c-45f1-8a69-663aa357620c.png" width="400" />


<sup><sub>1/14/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9884_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9884_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9884_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Portkey's AI Gateway: Access 100+ LLMs with Unified API
Summary: Portkey's AI Gateway functions as an interface between applications and hosted Large Language Models, enabling streamlined API requests to various providers. It features a unified API signature for over 100 LLMs, allowing developers to connect using the OpenAI API signature without code modifications. Additional features include automatic retries, fallbacks, load balancing, and multiple SDKs for easy integration. Configurable routing strategies offer customization for fallbacks, retries, and load balancing.

Link: https://github.com/Portkey-AI/gateway

<img src="/img/9010a57f-f609-41d0-984d-09bda68172c1.png" width="400" />


<sup><sub>1/13/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9877_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9877_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9877_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Improved Latent Space Representation with Variational Autoencoders
Summary: Variational AutoEncoders (VAEs) are an extension of classical autoencoders typically used for dimensionality reduction. While classical autoencoders only minimize the reconstruction loss, VAEs instead maximize a lower bound on the log-likelihood of the data. This results in a more continuous and centralized latent space, which is advantageous for generative tasks. The posterior distribution in VAEs is approximated by a diagonal Gaussian distribution with parameters \(\mu\) and \(\sigma\), and the KL divergence between this distribution and the standard Gaussian is used as a penalty in the loss function. The resulting latent space is more compact and smooth, allowing for interpolation between input images and other fun applications.

Link: https://avandekleut.github.io/vae/

<img src="/img/66a15480-74d5-46e4-b88c-d4d063bbc644.png" width="400" />


<sup><sub>1/9/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9835_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9835_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9835_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Harvard Offers 10 Free Online Courses on Data Science, Statistics, and Web Programming
Summary: Harvard University is offering a variety of free data science, statistics, and web programming courses. These courses cover a wide range of topics, from high-dimensional data analysis to understanding technology. The courses are taught by experts in the field and are designed to be accessible to learners of all levels.

Link: https://www.linkedin.com/posts/lauradrahanbennett_ai-machinelearning-datascience-activity-7146321506380218368-1nnL?utm_source=share&amp;utm_medium=member_android

<img src="/img/627da72a-a633-4ccd-8c15-65b286f75368.png" width="400" />


<sup><sub>1/8/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9816_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9816_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9816_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## JPMorgan AI Research Introduces DocLLM: A Lightweight Extension to Traditional Large Language Models for Generative Reasoning Over Documents with Rich Layouts
Summary: JPMorgan AI Research presents DocLLM, an extension of large language models designed for reasoning over visual documents. It combines textual semantics and spatial layout using bounding box coordinates, allowing efficient cross-modal interaction capture. The model is pre-trained with a modified self-supervised target addressing layout issues and fine-tuned with instruction data for tasks like form comprehension, table alignment, and visual question answering, showing significant performance gains.

Link: https://www.marktechpost.com/2024/01/05/jpmorgan-ai-research-introduces-docllm-a-lightweight-extension-to-traditional-large-language-models-tailored-for-generative-reasoning-over-documents-with-rich-layouts/?amp=

<img src="/img/e3156297-1b6f-4fe0-b942-2483d95d261c.png" width="400" />


<sup><sub>1/6/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9805_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9805_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9805_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## JPMorgan AI Research Introduces DocLLM, a Lightweight Extension to Traditional Large Language Models for Generative Reasoning Over Documents with Rich Layouts
Summary: JPMorgan AI Research has introduced DocLLM, a lightweight extension to traditional Large Language Models (LLMs) specifically tailored for generative reasoning over documents with rich layouts. DocLLM represents both text semantics and spatial layouts, leveraging bounding box coordinates acquired through optical character recognition (OCR) to add spatial layout information. It extends the self-attention mechanism of transformers to capture cross-modal interactions between text and layout. DocLLM has demonstrated significant performance gains on various document intelligence tasks, including form comprehension, table alignment, visual question answering, and key information extraction, highlighting its effectiveness in handling complex document structures and mixed data types.

Link: https://www.marktechpost.com/2024/01/05/jpmorgan-ai-research-introduces-docllm-a-lightweight-extension-to-traditional-large-language-models-tailored-for-generative-reasoning-over-documents-with-rich-layouts/?amp=

<img src="/img/c5ac700d-366a-404f-a3e3-51dbeaa6f74e.png" width="400" />


<sup><sub>1/6/2024 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9805_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9805_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9805_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## Curiosity, effort, ability, and luck are key factors in achieving great work. One should focus on something exciting that provides scope for great and unique work. It is recommended to choose a field, learn enough to reach the frontier of knowledge, notice gaps, and then explore promising ones.
Summary: This text describes the common traits of exceptionally productive people. The author asserts that the first step to excelling in a field is to choose a field that aligns with your natural aptitudes, interests, and offers ample opportunities for groundbreaking work. However, finding such a field is difficult, especially when you're young. Therefore, the author recommends experimenting with different fields and projects until you find one that truly excites you.

Once you've chosen a field, the next step is to learn as much as you can about it and identify knowledge gaps. Then, focus on filling those gaps by conducting research, asking questions, and seeking out experts in the field. The author emphasizes the importance of embracing strange or unconventional ideas, as these often lead to breakthroughs.

The author also stresses the significance of perseverance and hard work. Great work, they argue, often requires long hours and intense focus. However, it is important to avoid burnout by taking breaks and engaging in activities that recharge your energy.

To ensure consistency in your work, the author suggests setting clear goals and creating a schedule that allows for uninterrupted periods of focused work. Additionally, they recommend avoiding distractions and interruptions, both during work and during breaks.

To improve your work further, the author encourages seeking feedback from others, especially those who are knowledgeable in your field. Constructive criticism can help you identify areas where you can improve and refine your work.

Finally, the author highlights the importance of maintaining a curious and open mindset. By continuously seeking new knowledge and experiences, you can expand your understanding of the world and generate innovative ideas.

Link: https://paulgraham.com/greatwork.html

<img src="/img/46e14cdf-da78-48e6-90bb-10c9a4483a03.png" width="400" />


<sup><sub>12/28/2023 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9657_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9657_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=9657_0&tag=Experiments)<sub/><sup/>

<br/><br/>

## A List of Open-Source LLMs for Builders
Summary: This article presents a comprehensive list of open-source Large Language Models (LLMs) available for both commercial and research purposes. It includes models like Flan-U\u00b2, OpenChatKit, Cerebras-GPT, Pythia, Bloom & mTO, OpenAssistant, nanoT5, GeoV, Baize, Vicuna, Koala, GPT4All, Lit-LLaMA, Dolly, Dalai, Alpaca.cpp, Alpaca-LORA, and llama.cpp. While most of these models can be used commercially, Lit-LLaMA, Dolly, and OpenAssistant's offerings are restricted to non-commercial use. The article emphasizes that users should carefully consider their intended use case when selecting a model, as many require instruction tuning to perform effectively.

Link: https://www.linkedin.com/feed/update/urn:li:activity:7049789761728770049?utm_source=share&utm_medium=member_android

<img src="/img/ccc7d6d4-ae0a-4d05-9334-9fe130ed51dd.png" width="400" />


<sup><sub>4/8/2023 [Mark as read](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=8221_0&tag=isread) [Mark as BestOf](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=8221_0&tag=bestof) [Experiments](https://githublistbuilder.azurewebsites.net/api/TagSetter?articleid=8221_0&tag=Experiments)<sub/><sup/>

<br/><br/>

